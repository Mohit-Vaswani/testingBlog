# Datasets

- [Falcon Dataset](https://huggingface.co/datasets/tiiuae/falcon-refinedweb): A large English web dataset is utilized for training the Falcon LLM.

- [Music Caps](https://huggingface.co/datasets/google/MusicCaps) dataset contains 5,521 music examples, each of which is labeled with an English aspect list and a free text caption written by musicians.

- [MMLU](https://huggingface.co/datasets/cais/mmlu) (Multi-task Language Understanding) is a new benchmark designed to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. <a class="link" target="_blank" href="https://paperswithcode.com/dataset/mmlu">(Paper with Code)</a> 

- [MMMU](https://huggingface.co/datasets/MMMU/MMMU) (Massive Multi-discipline Multimodal Understanding) benchmark assesses multimodal models on college-level tasks, including image and text retrieval, question-answering, and language modeling. It gauges AI models' ability to understand and reason across diverse disciplines. <a class="link" target="_blank" href="https://mmmu-benchmark.github.io/">(website)</a> 

- [HumanEval](https://huggingface.co/datasets/openai_humaneval) is a benchmark for evaluating the multilingual ability of code generative models. <a class="link" target="_blank" href="https://paperswithcode.com/dataset/humaneval">(Paper with Code)</a> 

- [GSM8K](https://huggingface.co/datasets/gsm8k) is  high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning. <a class="link" target="_blank" href="https://paperswithcode.com/dataset/gsm8k">(Paper with Code)</a>  

import { Callout} from 'nextra-theme-docs'

<Callout emoji="⚠️">
  This section is under heavy development.
</Callout>