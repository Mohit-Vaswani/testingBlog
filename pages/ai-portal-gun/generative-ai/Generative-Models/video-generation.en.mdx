# Vedio Generation

AI video generation utilizes artificial intelligence to automatically produce video content. By understanding user input, it generates visual and audio elements, offering an efficient way to create videos for various applications.

<br />
import Image from 'next/image'
import myGif from 'public/gif/aiVedio.gif'

<Image src={myGif} alt="my gif" height="300" width="1000"/>

### Advancements

- [Make-A-Video](https://makeavideo.studio/) by Meta AI, is an AI system that generates high-quality video clips from text prompts. It leverages recent advancements in text-to-image generation technology and utilizes publicly available datasets for transparency, it empowers users to create content easily and can create videos from images or remix existing ones. <a class="link" target="_blank" href="https://arxiv.org/abs/2209.14792">(paper)</a> 

- [Emu Video](https://emu-video.metademolab.com/) and [Emu Edit](https://emu-edit.metademolab.com/) by Meta AI. Emu Video uses diffusion models to create high-quality videos from text prompts, outperforming previous methods in human evaluations. Meanwhile, Emu Edit is a versatile picture editing tool allowing detailed instructions for tasks like local/global edits, background manipulation, color/geometry transformations, detection, and segmentation. <a class="link" target="_blank" href="https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/">(blog)</a> <a class="link" target="_blank" href="https://arxiv.org/abs/2311.10709">(Emu Video paper)</a> <a class="link" target="_blank" href="https://emu-edit.metademolab.com/assets/emu_edit.pdf">(Emu Edit paper)</a>

- [Stable Video Diffusion](https://stability.ai/stable-video) by Stability AI, a model that converts text and image inputs into dynamic scenes, bringing concepts to life in cinematic form. Released as two image-to-video models, it offers video durations of 2-5 seconds, frame rates of up to 30 FPS, and processing times of 2 minutes or less. <a class="link" target="_blank" href="https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets">(paper)</a>

- [ProPainter](https://shangchenzhou.com/projects/ProPainter/), developed by NTU's S-Lab team, is an open-source algorithm for video editing and repair. It employs propagation and transformer models to enhance video inpainting quality, addressing tasks like object and watermark removal, video mask completion, and expansion. <a class="link" target="_blank" href="https://github.com/sczhou/ProPainter">(code)</a> <a class="link" target="_blank" href="https://arxiv.org/abs/2309.03897">(paper)</a> <a class="link" target="_blank" href="https://huggingface.co/spaces/sczhou/ProPainter">(demo)</a>

### Article & Papers

- [Imagen Video: High Definition Video Generation with Diffusion Models](https://arxiv.org/abs/2210.02303) (2022) by Google, is a paper introducing a high-definition video generation method using diffusion models. The technique, based on sequential noise addition to latent representations, achieves top results in video synthesis benchmarks. <a class="link" target="_blank" href="https://imagen.research.google/video/">(website)</a>


### Reference

- [Papers with Code](https://paperswithcode.com/): Collection of papers and benchmarks related to <a class="link" target="_blank" href="https://paperswithcode.com/task/video-generation">video generation</a>, <a class="link" target="_blank" href="https://paperswithcode.com/task/text-to-video-generation">Text-to-Video Generation</a> and <a class="link" target="_blank" href="https://paperswithcode.com/task/image-to-video">Image to Video Generation</a>.

- [Camenduru's GitHub Video ML Papers](https://github.com/camenduru#-video-ml-papers): This collection comprises repositories containing video machine learning papers. It also encompasses projects related to text-to-video synthesis, diffusion models, and video retalking.

- [Camenduru's 3D Motion Papers](https://github.com/camenduru#-3d-motion-papers): This collection contains repositories on 3D motion papers, includes projects like MotionDiffuse, NIKI, PHALP, DWPose, 4D-Humans, vid2avatar, and PARE.

